{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Mateo Ignacio\n",
    "- Samuel Piltch\n",
    "- Nate del Rosario üêê\n",
    "- Lisa Hwang\n",
    "- Geovaunii D. White\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we‚Äôve never worked with audio data or classification of audio data we wanted to try a binary example. We ask the question: can we classify animal noises using audio analysis?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our project, we will be working to create an algorithm that can classify animal noises. Although with the average human's capabilities, it should be easy to discern the difference between a cat's meow and a dog's bark, this is not as simple to program with technology. After some initial research, there are differences in a dog's bark and a cat's meow that can be distinguished by a machine. This is not a question that is unique, as there have been many studies and models that have been trained in a similar capacity. \n",
    "\n",
    "For example, there is a study in which scientists created a neural network that has the ability to classify animal sounds. The algorithm was built with data consisting of recordings of marmoset monkeys in a loud environment. Their network is able to identify the animal that made the noise as well as the call type, by using spectrogram images [^1]. In another study from 2020, an algorithm is able to classify an animal sound from its dissimilarity to another animal sound. The classifier system was produced with Siamese neural networks (SNNs) and support vector machines (SVMs) to identify dissimilarity spaces of spectrograms [^2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^1]: Tuomas Oikarinen, Karthik Srinivasan, Olivia Meisner, Julia B. Hyman, Shivangi Parmar, Adrian Fanucci-Kiss, Robert Desimone, Rogier Landman, Guoping Feng; Deep convolutional network for animal sound classification and source attribution using dual audio recordings. J Acoust Soc Am 1 February 2019; 145 (2): 654‚Äì662. https://doi.org/10.1121/1.5087827\n",
    "\n",
    "[^2]: Nanni L, Brahnam S, Lumini A, Maguolo G. Animal Sound Classification Using Dissimilarity Spaces. Applied Sciences. 2020; 10(23):8578. https://doi.org/10.3390/app10238578"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The noises made by dogs and cats can be used for classification strictly through analyzing audio samples. If numerical data is extracted from the audio then models can be trained to predict the species making the noise.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Variables we would ideally have are audio length, decibels (how loud), species classification as a response variable.  (supervised dataset?)In the best situation the .wav files would be accompanied by a csv or json of numerical already preprocessed so we would not have to clean any of the data. For audio a dataset that is sufficiently large require less observations than necessary for other models since we would have to account for memory issues and such so around 2000 or more observations would be ideal. The observations would be sounds dogs and cats make, like meows, barks and howls. Again memory is theoretically an issue since long audio files could create noise and issues with memory as typically large files are not necessary and a compact csv or json is all that is needed.\n",
    "2. We have found a dataset through Kaggle that is a sample from a larger dataset of sounds including planes, humans, and traffic. This data is already readily available and it includes .wav files. Since there are no accompanying csv files we must make the table of variables ourselves which may prove challenging. The preprocessing will probably take the most time. This data is from the AE-Dataset creator which itself was made from FreeSound. Naoya Takahashi, Michael Gygli, Beat Pfister and Luc Van Gool, \"Deep Convolutional Neural Networks and Data Augmentation for Acoustic Event Recognition\", Proc. Interspeech 2016, San Fransisco."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ethical concerns in the process of gathering data on animals, since there is no guaranteed method of retrieving an animal's consent. The National Committee for Research Ethics in Science and Technology (NENT) has 10 guidelines for impacted animals involving experiments on animals [^3].\n",
    "\n",
    "The cat and dog noises are derived from the website, ‚ÄúFreeSound,‚Äù which highlights in its policy that the utilization of the sounds may vary with which license is associated with them [^4]. Given that, one of the licenses requires that the user mention the author who uploaded the sound, otherwise the sounds may be used freely at one‚Äôs own discretion. By uploading a sound to the website ‚ÄúFreeSound‚Äù one consents to their sound being potentially used by others following the guidelines of the license associated with them.\n",
    "\n",
    "The data will be collected from the website ‚Äúkaggle‚Äù which is stored as WAV files in a CSV file. \n",
    "Our audio files have the potential to be exclusive of certain breeds of dogs or cats, as there is a limited amount of audio files in our dataset. Therefore, there is room for biases and misrepresentation of all dogs and cats. Additionally, as the project deals with previously collected data there will be no need to anticipate data that is incomplete or unfinished due to an opting out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^3]: (2019, July 8). Ethical Guidelines for the Use of Animals in Research. Retrieved May 3, 2023, from https://www.forskningsetikk.no/en/guidelines/science-and-technology/ethical-guidelines-for-the-use-of-animals-in-research/\n",
    "\n",
    "[^4]: (n.d.). Freesound - Freesound. Retrieved May 3, 2023, from https://freesound.org/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* Everyone should contribute something, and no one or few people should contribute too much to allow others to add their own contributions.\n",
    "\n",
    "* When one person writes code or makes a change to a part of the project, it should be reviewed by at least one other group member (preferably most or all)\n",
    "\n",
    "* Code Review SHOULD be done through pull requests \n",
    "\n",
    "* Every member will create a branch and make their changes there for version control\n",
    "\n",
    "* We will communicate through text and on call (when free)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your team's specific project timeline. An example timeline has been provided. Changes the dates, times, names, and details to fit your group's plan.\n",
    "\n",
    "If you think you will need any special resources or training outside what we have covered in COGS 108 to solve your problem, then your proposal should state these clearly. For example, if you have selected a problem that involves implementing multiple neural networks, please state this so we can make sure you know what you‚Äôre doing and so we can point you to resources you will need to implement your project. Note that you are not required to use outside methods.\n",
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 5/10  |  6 PM | Read & Think about COGS 108 expectations; begin discussing and implementing Data Wrangling  | Go over shortcomings and successes, check that the data is in the correct format we want | \n",
    "| 5/17  |  6 PM |  Finalize data cleaning, wrangling, storage | Begin brainstorming EDA methods | \n",
    "| 5/24  | 6 PM  | Iterate  | Discuss  possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 5/31  | 6 PM  | Finish EDA and begin model selection | Assign Tickets  |\n",
    "| 6/7   | 6 PM  | Code Review and begin implementing and testing | AGILE and go over findings |\n",
    "| 6/14  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Wasp)| Discuss/edit full project |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
