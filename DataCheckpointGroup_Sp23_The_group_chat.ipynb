{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Mateo Ignacio\n",
    "- Samuel Piltch\n",
    "- Nate del Rosario üêê\n",
    "- Lisa Hwang\n",
    "- Geovaunii D. White"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we‚Äôve never worked with audio data or classification of audio data we wanted to try a binary example. We ask the question: can we classify animal noises using audio analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your dataset information here*\n",
    "\n",
    "(Copy this information for each dataset)\n",
    "- Dataset Name: Audio Cats and Dogs\n",
    "- Link to the dataset: [data](https://www.kaggle.com/datasets/mmoreaux/audio-cats-and-dogs)\n",
    "- Number of observations: 277\n",
    "\n",
    "The dataset consists of 277 wav files of cats and dogs. In addition, a supplemental csv of train/test splits has been provided.\n",
    "A deeper dive into the data can be found [here](https://www.kaggle.com/code/mmoreaux/a-look-into-the-data?scriptVersionId=1573551)\n",
    "where we can see that the wav files can be processed into more usable forms such as numpy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b6/6kqnsjc91y58sq2f0plvqs8m0000gn/T/ipykernel_89486/3543922915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
=======
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 20:02:46.211610: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
>>>>>>> b2cd113 (Addition: extract_features(), add_features())
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# audio plot \n",
    "from scipy.io import wavfile as wav\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "\n",
    "# DL libraries that we may or may not need\n",
    "import tensorflow\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.callbacks import Callback,EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Flatten, Dense,GlobalAveragePooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in Total, there are 164 cats and 115 dogs\n",
      "in X_train, there are 108 cats and 78 dogs\n",
      "in X_test, there are 56 cats and 37 dogs\n"
     ]
    }
   ],
   "source": [
    "# List the wav files\n",
    "ROOT_DIR = 'data/cats_dogs/'\n",
    "X_path = os.listdir(ROOT_DIR)\n",
    "\n",
    "# change y to int values\n",
    "y = [0 if 'cat' in f else 1 for f in X_path] \n",
    "\n",
    "# Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_path, y, test_size=0.33)\n",
    "\n",
    "print(f\"In Total, there are {len(y) - sum(y)} cats and {sum(y)} dogs.\")\n",
    "print(f\"In X_train, there are {len(y_train) - sum(y_train)} cats and {sum(y_train)} dogs.\")\n",
    "print(f\"Iin X_test, there are {len(y_test) - sum(y_test)} cats and { sum(y_test)} dogs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with wav files, we will need to handle them differently as they are not in numerical form.\n",
    "Our approach is as follows:\n",
    "- create a DataFrame of filepaths and assign labels to our data\n",
    "- for each observation, we use the filepath to generate a new set of data, the audio features and statistics for that particular wav file. \n",
    "This is a similar approach to [getting the song uri from the general dataset here](https://developer.spotify.com/documentation/web-api/reference/get-several-audio-features) and producing a new feature series for it.\n",
    "- we will then merge these two DataFrames using an outer join to combine all the columns from both. This process will ideally not require much imputation since the two DataFrames will have the same column observations to merge on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets read in our train test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_cat</th>\n",
       "      <th>test_dog</th>\n",
       "      <th>train_cat</th>\n",
       "      <th>train_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat_22.wav</td>\n",
       "      <td>dog_barking_97.wav</td>\n",
       "      <td>cat_99.wav</td>\n",
       "      <td>dog_barking_33.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat_116.wav</td>\n",
       "      <td>dog_barking_0.wav</td>\n",
       "      <td>cat_54.wav</td>\n",
       "      <td>dog_barking_86.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat_155.wav</td>\n",
       "      <td>dog_barking_93.wav</td>\n",
       "      <td>cat_34.wav</td>\n",
       "      <td>dog_barking_45.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat_58.wav</td>\n",
       "      <td>dog_barking_10.wav</td>\n",
       "      <td>cat_132.wav</td>\n",
       "      <td>dog_barking_76.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat_77.wav</td>\n",
       "      <td>dog_barking_26.wav</td>\n",
       "      <td>cat_124.wav</td>\n",
       "      <td>dog_barking_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cat_15.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cat_88.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cat_73.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cat_32.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cat_113.wav</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        test_cat            test_dog    train_cat           train_dog\n",
       "0     cat_22.wav  dog_barking_97.wav   cat_99.wav  dog_barking_33.wav\n",
       "1    cat_116.wav   dog_barking_0.wav   cat_54.wav  dog_barking_86.wav\n",
       "2    cat_155.wav  dog_barking_93.wav   cat_34.wav  dog_barking_45.wav\n",
       "3     cat_58.wav  dog_barking_10.wav  cat_132.wav  dog_barking_76.wav\n",
       "4     cat_77.wav  dog_barking_26.wav  cat_124.wav   dog_barking_4.wav\n",
       "..           ...                 ...          ...                 ...\n",
       "110          NaN                 NaN   cat_15.wav                 NaN\n",
       "111          NaN                 NaN   cat_88.wav                 NaN\n",
       "112          NaN                 NaN   cat_73.wav                 NaN\n",
       "113          NaN                 NaN   cat_32.wav                 NaN\n",
       "114          NaN                 NaN  cat_113.wav                 NaN\n",
       "\n",
       "[115 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_test_split.csv')\n",
    "df = df[['test_cat', 'test_dog', 'train_cat', 'train_dog']]\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are a lot of NaN values because the partitions are different sizes for each. We can also see that this DataFrame is not in the most useable format, so we will load our data into a different form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/cats_dogs/cat_74.wav</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>data/cats_dogs/cat_163.wav</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>data/cats_dogs/cat_31.wav</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>data/cats_dogs/cat_25.wav</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>data/cats_dogs/cat_19.wav</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>data/cats_dogs/dog_barking_112.wav</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>data/cats_dogs/dog_barking_64.wav</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>data/cats_dogs/dog_barking_3.wav</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>data/cats_dogs/dog_barking_36.wav</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>data/cats_dogs/dog_barking_105.wav</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              file_path label\n",
       "0             data/cats_dogs/cat_74.wav   cat\n",
       "146          data/cats_dogs/cat_163.wav   cat\n",
       "149           data/cats_dogs/cat_31.wav   cat\n",
       "151           data/cats_dogs/cat_25.wav   cat\n",
       "152           data/cats_dogs/cat_19.wav   cat\n",
       "..                                  ...   ...\n",
       "184  data/cats_dogs/dog_barking_112.wav   dog\n",
       "51    data/cats_dogs/dog_barking_64.wav   dog\n",
       "134    data/cats_dogs/dog_barking_3.wav   dog\n",
       "128   data/cats_dogs/dog_barking_36.wav   dog\n",
       "211  data/cats_dogs/dog_barking_105.wav   dog\n",
       "\n",
       "[277 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = 'data/cats_dogs'\n",
    "labels = ['cat', 'dog']\n",
    "data = []\n",
    "\n",
    "# Iterate through the files in the base directory\n",
    "for filename in os.listdir(base_dir):\n",
    "    if filename.endswith('.wav'):\n",
    "        file_path = os.path.join(base_dir, filename)\n",
    "\n",
    "        # Determine the label based on the filename\n",
    "        if filename.startswith('cat'):\n",
    "            label = 'cat'\n",
    "        elif filename.startswith('dog'):\n",
    "            label = 'dog'\n",
    "        else:\n",
    "            # Skip the file if the label cannot be determined\n",
    "            continue\n",
    "\n",
    "        # Append the file path and label to the data list\n",
    "        data.append({'file_path': file_path, 'label': label})\n",
    "\n",
    "# Convert the data list into a pandas DataFrame\n",
    "cats_and_dogs = pd.DataFrame(data).sort_values(by = 'label', ascending=True)\n",
    "cats_and_dogs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this form is much neater since we are now dealing with labelled data, which will make binary classification easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_path\n",
       "label           \n",
       "cat          164\n",
       "dog          113"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = cats_and_dogs.groupby('label').agg('count')\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    \"\"\"Idk what audio features to extract these are the ones that were recommended but we should get more\"\"\"\n",
    "    \n",
    "    y, sr = librosa.load(file_path)\n",
    "\n",
    "    # Extract MFCC features\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "\n",
    "    # Extract chroma features\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_mean = np.mean(chroma, axis=1)\n",
    "\n",
    "    # Extract spectral contrast features\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spec_contrast_mean = np.mean(spec_contrast, axis=1)\n",
    "\n",
    "    features = np.concatenate([mfcc_mean, chroma_mean, spec_contrast_mean])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(cats_and_dogs):\n",
    "    \"\"\"Adds certain features to the existing dataset\"\"\"\n",
    "    \n",
    "    # Assuming cats_and_dogs is a DataFrame containing file paths under the 'file_path' column\n",
    "    num_rows = len(cats_and_dogs)\n",
    "\n",
    "    # Create empty NumPy arrays for storing features\n",
    "    mfcc_features = np.empty((num_rows, 20))\n",
    "    chroma_features = np.empty((num_rows, 12))\n",
    "    spec_contrast_features = np.empty((num_rows, 7))\n",
    "\n",
    "    # Iterate through the rows of the DataFrame, extract features for the current file\n",
    "    for index, row in cats_and_dogs.iterrows():\n",
    "        file_path = row['file_path']\n",
    "        features = extract_features(file_path)\n",
    "\n",
    "        # Check if the index is within bounds (will error otherwise)\n",
    "        if index < num_rows:\n",
    "            # Add the extracted features to the respective NumPy arrays\n",
    "            mfcc_features[index] = features[:20] \n",
    "            chroma_features[index] = features[20:32]  \n",
    "            spec_contrast_features[index] = features[32:]  \n",
    "\n",
    "    # Add the extracted features as new columns in the DataFrame\n",
    "    cats_and_dogs['mfcc'] = list(mfcc_features)\n",
    "    cats_and_dogs['chroma'] = list(chroma_features)\n",
    "    cats_and_dogs['spec_contrast'] = list(spec_contrast_features)\n",
    "\n",
    "cats_and_dogs = add_features(cats_and_dogs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0c5cb6bf509a02cef9c56bf2eb97e86fe98bb4322bfa6beb984e4c134a4af93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
